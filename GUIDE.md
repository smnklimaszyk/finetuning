# ğŸ¥ Medical Diagnosis Model Finetuning

## Datenschutzkonformes Finetuning eines Small Language Models fÃ¼r medizinische DiagnoseunterstÃ¼tzung

---

# ğŸ“– VOLLSTÃ„NDIGER ENTWICKLER-GUIDE

Dieser Guide fÃ¼hrt dich Schritt fÃ¼r Schritt durch die komplette Entwicklung und Nutzung dieses MLOps-Projekts.
Er ist fÃ¼r Entwickler geschrieben, die ein tiefes VerstÃ¤ndnis fÃ¼r Machine Learning Engineering entwickeln mÃ¶chten.

---

## ğŸ“‹ Inhaltsverzeichnis

1. [ProjektÃ¼bersicht & Architektur](#1-projektÃ¼bersicht--architektur)
2. [Theoretische Grundlagen](#2-theoretische-grundlagen)
3. [Projektstruktur ErklÃ¤rt](#3-projektstruktur-erklÃ¤rt)
4. [Konfigurationssystem](#4-konfigurationssystem)
5. [Datenverarbeitungs-Pipeline](#5-datenverarbeitungs-pipeline)
6. [Modell-Architektur](#6-modell-architektur)
7. [Training mit LoRA](#7-training-mit-lora)
8. [Evaluation & Metriken](#8-evaluation--metriken)
9. [Experiment-Workflow](#9-experiment-workflow)
10. [Best Practices & Troubleshooting](#10-best-practices--troubleshooting)

---

## 1. ProjektÃ¼bersicht & Architektur

### 1.1 Was macht dieses Projekt?

Dieses Projekt entwickelt ein **spezialisiertes KI-Modell** zur UnterstÃ¼tzung von Ã„rzten bei der Diagnosestellung.
Basierend auf Arzt-Patienten-Dialogen schlÃ¤gt das Modell passende **ICD-10 Diagnose-Codes** vor.

**Der Workflow:**

```
Arzt-Patienten-Dialog â†’ KI-Modell â†’ ICD-10 Code Vorschlag
```

### 1.2 Die drei Modell-AnsÃ¤tze

Wir vergleichen drei verschiedene AnsÃ¤tze:

| Ansatz            | Beschreibung                    | Vorteile                                 | Nachteile                           |
| ----------------- | ------------------------------- | ---------------------------------------- | ----------------------------------- |
| **Baseline LLM**  | GroÃŸes Modell mit System-Prompt | Generelles Wissen, keine Anpassung nÃ¶tig | Langsam, teuer, Datenschutz-Risiken |
| **Baseline SLM**  | Kleines Modell ohne Finetuning  | Schnell, gÃ¼nstig, lokal                  | Weniger spezialisiert               |
| **Finetuned SLM** | Kleines Modell nach Training    | Schnell, spezialisiert, lokal            | Trainingsaufwand                    |

### 1.3 Architektur-Ãœbersicht

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MAIN PIPELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Data    â”‚ â†’ â”‚  Model   â”‚ â†’ â”‚ Training â”‚ â†’ â”‚  Evaluation  â”‚ â”‚
â”‚  â”‚  Layer   â”‚   â”‚  Layer   â”‚   â”‚  Layer   â”‚   â”‚    Layer     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â†“              â†“              â†“               â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   CONFIG LAYER                           â”‚  â”‚
â”‚  â”‚         (Zentrale Konfiguration fÃ¼r alles)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Theoretische Grundlagen

### 2.1 Was ist Finetuning?

**Finetuning** ist das Anpassen eines vortrainierten Modells auf eine spezifische Aufgabe.

```
Vortrainiertes Modell     Finetuning        Spezialisiertes Modell
(generelles Wissen)    â†’  (+ Domain-Daten) â†’  (+ DomÃ¤nen-Wissen)
```

**Warum Finetuning statt Training von Grund auf?**

- Vortrainierte Modelle haben bereits SprachverstÃ¤ndnis gelernt
- Finetuning braucht viel weniger Daten (1000e vs. Milliarden)
- Schneller und gÃ¼nstiger

### 2.2 Was ist LoRA?

**LoRA (Low-Rank Adaptation)** ist eine effiziente Finetuning-Methode.

**Das Problem:** Normale Finetuning-Methoden Ã¤ndern alle Parameter (Milliarden!).

**Die LÃ¶sung:** LoRA trainiert nur kleine "Adapter"-Matrizen:

```
Original-Matrix W:    [1000 x 1000] = 1.000.000 Parameter
LoRA-Matrizen A, B:   [1000 x 16] + [16 x 1000] = 32.000 Parameter
                                                   = 3.2% der Original-GrÃ¶ÃŸe!
```

**LoRA-Formel:**

```
W' = W + Î”W = W + A Ã— B
```

Wobei:

- `W` = Originale Gewichte (eingefroren, nicht trainiert)
- `A` = Down-Projection (Input â†’ niedrig-dimensionaler Raum)
- `B` = Up-Projection (niedrig-dimensionaler Raum â†’ Output)
- `r` = Rank (typisch 8-64, kontrolliert KapazitÃ¤t)

### 2.3 ICD-10 Klassifikation

**ICD-10** (International Classification of Diseases) ist das weltweite Standard-System fÃ¼r Diagnosen.

**Aufbau:**

```
J06.9
â”‚â”‚â”‚ â”‚
â”‚â”‚â”‚ â””â”€â”€ Weitere Spezifikation (.9 = nicht nÃ¤her bezeichnet)
â”‚â”‚â”‚
â”‚â”‚â””â”€â”€â”€â”€ Hauptgruppe innerhalb Kapitel (06 = Akute Infektionen obere Atemwege)
â”‚â”‚
â”‚â””â”€â”€â”€â”€â”€ Kapitel-Buchstabe (J = Atmungssystem)
â”‚
â””â”€â”€â”€â”€â”€â”€ Hierarchie-Ebene
```

**Beispiele:**

- `J06.9` = Akute Infektion der oberen Atemwege, nicht nÃ¤her bezeichnet
- `I10` = Essentielle Hypertonie (Bluthochdruck)
- `G43.9` = MigrÃ¤ne, nicht nÃ¤her bezeichnet

---

## 3. Projektstruktur ErklÃ¤rt

### 3.1 Verzeichnisstruktur

```
finetuning/
â”œâ”€â”€ src/                    # ğŸ“¦ Python Packages (src-layout)
â”‚   â”œâ”€â”€ config/            # ğŸ”§ Konfiguration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ base_config.py # Alle Hyperparameter und Settings
â”‚   â”‚
â”‚   â”œâ”€â”€ data/              # ğŸ“Š Datenverarbeitung
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py # LÃ¤dt Daten von HuggingFace
â”‚   â”‚   â””â”€â”€ data_processor.py  # Tokenisierung und Formatierung
â”‚   â”‚
â”‚   â”œâ”€â”€ models/            # ğŸ¤– Modell-Wrapper
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_model.py  # Abstrakte Basisklasse
â”‚   â”‚   â”œâ”€â”€ llm_model.py   # Large Language Model Wrapper
â”‚   â”‚   â””â”€â”€ slm_model.py   # Small Language Model Wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ training/          # ğŸ‹ï¸ Training
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ trainer.py     # Finetuning mit LoRA
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/        # ğŸ“ˆ Auswertung
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py     # Metriken-Berechnung
â”‚   â”‚   â””â”€â”€ visualization.py  # Plots und Reports
â”‚   â”‚
â”‚   â””â”€â”€ utils/             # ğŸ› ï¸ Hilfsfunktionen
â”‚       â””â”€â”€ __init__.py    # Logging, Helpers
â”‚
â”œâ”€â”€ tests/                 # âœ… Unit Tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ data/                  # ğŸ“Š Daten-Outputs (raw, processed, cache)
â”œâ”€â”€ models/                # ğŸ’¾ Modell-Checkpoints und Finetuned Models
â”œâ”€â”€ notebooks/             # ğŸ““ Jupyter Notebooks
â”œâ”€â”€ experiments/           # ğŸ§ª Experiment Tracking (MLflow)
â”œâ”€â”€ outputs/               # ğŸ“ Outputs (logs, metrics, plots, reports)
â”‚
â”œâ”€â”€ main.py               # ğŸš€ Haupt-Pipeline
â”œâ”€â”€ pyproject.toml        # ğŸ“¦ Dependencies
â”œâ”€â”€ .gitignore           # Git-Ignore
â””â”€â”€ GUIDE.md             # ğŸ“– Dieser Guide
```

### 3.2 Warum src-layout?

Diese Struktur folgt **MLOps Best Practices** und verwendet das **src-layout**:

1. **Saubere Trennung:** Code (src/) vs. Daten/Outputs (Projekt-Root)
2. **Build-Tool KompatibilitÃ¤t:** setuptools, pip, uv funktionieren problemlos
3. **Keine versehentlichen Imports:** Nur installierte Packages sind importierbar
4. **Separation of Concerns:** Jedes Modul hat eine klare Verantwortung
5. **Testbarkeit:** Klare Interfaces ermÃ¶glichen Unit Tests
6. **Reproduzierbarkeit:** Experimente sind nachvollziehbar

---

## 4. Konfigurationssystem

### 4.1 Datei: `src/config/base_config.py`

Das Konfigurationssystem nutzt **Pydantic** fÃ¼r type-safe Konfigurationen.

**Warum Pydantic?**

- Automatische Typvalidierung
- Defaults und Overrides
- Serialisierung (JSON speichern/laden)
- IDE-UnterstÃ¼tzung (Autocomplete)

### 4.2 Wichtige Konfigurationsklassen

#### DataConfig

```python
class DataConfig(BaseModel):
    dataset_name: str = "Ahmad0067/MedSynth"  # HuggingFace Dataset
    train_ratio: float = 0.7   # 70% fÃ¼r Training
    val_ratio: float = 0.15    # 15% fÃ¼r Validation
    test_ratio: float = 0.15   # 15% fÃ¼r finale Tests
    max_sequence_length: int = 512  # Max Token-LÃ¤nge
    batch_size: int = 8
```

**ErklÃ¤rung der Split-Ratios:**

- **Training (70%):** Das Modell lernt von diesen Daten
- **Validation (15%):** Zum Tunen von Hyperparametern und Early Stopping
- **Test (15%):** Finale Evaluation - NIEMALS wÃ¤hrend Training nutzen!

#### TrainingConfig

```python
class TrainingConfig(BaseModel):
    # Wichtigste Hyperparameter
    num_epochs: int = 3              # DurchlÃ¤ufe durch Datensatz
    learning_rate: float = 2e-5      # SchrittgrÃ¶ÃŸe beim Lernen
    warmup_steps: int = 500          # Langsamer Start
    weight_decay: float = 0.01       # L2-Regularisierung

    # LoRA-Konfiguration
    use_lora: bool = True
    lora_r: int = 16                 # Rank (8-64 typisch)
    lora_alpha: int = 32             # Scaling-Faktor
    lora_dropout: float = 0.05       # Regularisierung
```

### 4.3 Hyperparameter-ErklÃ¤rungen

| Parameter               | Typischer Wert | Bedeutung                          | Effekt wenn zu hoch            | Effekt wenn zu niedrig |
| ----------------------- | -------------- | ---------------------------------- | ------------------------------ | ---------------------- |
| `learning_rate`         | 1e-5 bis 5e-5  | Wie stark werden Weights angepasst | Instabiles Training, Divergenz | Zu langsames Lernen    |
| `num_epochs`            | 1-5            | Anzahl DurchlÃ¤ufe                  | Overfitting                    | Underfitting           |
| `warmup_steps`          | 500-2000       | Schritte zum Hochfahren der LR     | Zu langsamer Start             | Instabiler Anfang      |
| `weight_decay`          | 0.01-0.1       | L2-Regularisierung                 | Zu starke Regularisierung      | Overfitting            |
| `lora_r`                | 8-64           | LoRA Rank/KapazitÃ¤t                | Mehr Memory, evtl. Overfitting | Zu wenig KapazitÃ¤t     |
| `lora_alpha`            | 2\*r           | LoRA Scaling                       | StÃ¤rkere Adaptation            | SchwÃ¤chere Adaptation  |
| `batch_size`            | 4-32           | Samples pro Schritt                | Memory-Fehler                  | Langsam, instabil      |
| `gradient_accumulation` | 1-8            | Simuliert grÃ¶ÃŸere Batches          | Langsamer                      | Weniger stabil         |

**Die "effektive Batch-GrÃ¶ÃŸe":**

```
Effektive Batch Size = batch_size Ã— gradient_accumulation_steps Ã— num_gpus

Beispiel: 4 Ã— 4 Ã— 1 = 16 effektive Batch Size
```

---

## 5. Datenverarbeitungs-Pipeline

### 5.1 Datei: `data/data_loader.py`

Diese Datei lÃ¤dt den MedSynth-Datensatz von HuggingFace.

**MedSynth-Datensatz:**

- Synthetische Arzt-Patienten-Dialoge
- ICD-10 Diagnose-Codes
- Ca. 50.000 Beispiele

**Wichtige Methoden:**

```python
class MedSynthDataLoader:
    def load(self) -> Dataset:
        """LÃ¤dt Dataset von HuggingFace Hub."""

    def get_statistics(self) -> Dict:
        """Berechnet Statistiken (LÃ¤ngen, Verteilungen)."""

    def validate_dataset(self) -> bool:
        """PrÃ¼ft ob Dataset erwartete Struktur hat."""
```

### 5.2 Datei: `data/data_processor.py`

Hier werden die Rohdaten in ein fÃ¼r das Modell verstÃ¤ndliches Format gebracht.

**Der Verarbeitungsprozess:**

```
Roher Dialog           Formatierung           Tokenisierung
"Patient: ..." â†’  "[SYSTEM] Du bist..." â†’ [101, 234, 567, ...]
                  "[USER] Dialog..."       (Token IDs)
                  "[ASSISTANT] J06.9"
```

**Wichtige Konzepte:**

#### Tokenisierung

Tokenisierung wandelt Text in Zahlen um:

```
"Ich habe Kopfschmerzen"
â†’ ["Ich", "habe", "Kopf", "##schmerzen"]  (Subword Tokenization)
â†’ [1234, 5678, 9012, 3456]                 (Token IDs)
```

#### Chat-Templates

Moderne Modelle erwarten spezielle Formatierungen:

```python
# Phi-3 Format
<|system|>
Du bist ein medizinisches Assistenzsystem.
<|end|>
<|user|>
Analysiere diesen Dialog...
<|end|>
<|assistant|>
J06.9
<|end|>
```

### 5.3 Train/Val/Test Split

```python
def split_dataset(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """
    Warum 3 Splits?

    Training (70%): Modell lernt von diesen Daten
    â†“
    Validation (15%): PrÃ¼ft Fortschritt WÃ„HREND Training
                      - Hyperparameter-Tuning
                      - Early Stopping
    â†“
    Test (15%): Finale Evaluation NACH Training
                - Nur EINMAL nutzen!
                - Niemals fÃ¼r Entscheidungen wÃ¤hrend Training
    """
```

---

## 6. Modell-Architektur

### 6.1 Datei: `models/base_model.py`

Definiert die abstrakte Schnittstelle fÃ¼r alle Modelle.

**Design Pattern: Strategy Pattern**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  BaseModel   â”‚  (Abstract)
                    â”‚  - predict() â”‚
                    â”‚  - load()    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†‘
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“                           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   LLMModel   â”‚           â”‚   SLMModel   â”‚
    â”‚   (GroÃŸ)     â”‚           â”‚   (Klein)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vorteile:**

- Einheitliche Schnittstelle fÃ¼r alle Modelle
- Einfacher Austausch von Modellen
- Konsistente Evaluation

### 6.2 Datei: `models/llm_model.py`

Wrapper fÃ¼r Large Language Models.

**Wichtige Features:**

#### 4-bit Quantisierung

```python
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,           # Aktiviert 4-bit Quantisierung
    bnb_4bit_compute_dtype=torch.float16,  # Rechentyp
    bnb_4bit_use_double_quant=True,  # Nested Quantization
    bnb_4bit_quant_type="nf4"    # Normal Float 4-bit
)
```

**Was ist Quantisierung?**

```
Original (float32):    32 bit pro Parameter  â†’ 100% Memory
Half Precision (fp16): 16 bit pro Parameter  â†’ 50% Memory
4-bit Quantisierung:   4 bit pro Parameter   â†’ 12.5% Memory
```

**Trade-off:** Weniger Memory, minimal schlechtere QualitÃ¤t.

#### Generation-Parameter

```python
outputs = model.generate(
    max_new_tokens=256,      # Max AusgabelÃ¤nge
    temperature=0.7,         # KreativitÃ¤t (0=deterministisch, 1=kreativ)
    top_p=0.9,              # Nucleus Sampling
    top_k=50,               # Top-K Sampling
    repetition_penalty=1.1,  # Verhindert Wiederholungen
)
```

**Sampling-Strategien erklÃ¤rt:**

| Strategie                      | Beschreibung                       | Wann nutzen?                      |
| ------------------------------ | ---------------------------------- | --------------------------------- |
| **Greedy** (`do_sample=False`) | Immer wahrscheinlichstes Token     | Deterministische Ergebnisse nÃ¶tig |
| **Temperature**                | Flacht Probability-Verteilung ab   | Kreativere Ausgaben               |
| **Top-K**                      | Nur aus K besten Tokens wÃ¤hlen     | Verhindert "verrÃ¼ckte" Tokens     |
| **Top-p (Nucleus)**            | Aus kleinster Menge die p% abdeckt | Dynamischer als Top-K             |

---

## 7. Training mit LoRA

### 7.1 Datei: `training/trainer.py`

Implementiert das Finetuning mit Parameter-Efficient Fine-Tuning (PEFT).

### 7.2 LoRA im Detail

```python
lora_config = LoraConfig(
    r=16,                    # Rank - KapazitÃ¤t der Adapter
    lora_alpha=32,           # Scaling-Faktor
    lora_dropout=0.05,       # Regularisierung
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],  # Welche Layer
    task_type=TaskType.CAUSAL_LM,  # Aufgabentyp
)
```

**Welche Layer werden adaptiert?**

```
Transformer Block
â”œâ”€â”€ Self-Attention
â”‚   â”œâ”€â”€ q_proj (Query)      â† LoRA Adapter
â”‚   â”œâ”€â”€ k_proj (Key)        â† LoRA Adapter
â”‚   â”œâ”€â”€ v_proj (Value)      â† LoRA Adapter
â”‚   â””â”€â”€ o_proj (Output)     â† LoRA Adapter
â”œâ”€â”€ MLP
â”‚   â”œâ”€â”€ gate_proj
â”‚   â”œâ”€â”€ up_proj
â”‚   â””â”€â”€ down_proj
```

**Parameter-Einsparung Beispiel (Phi-3 Mini, 3.8B Parameter):**

```
Ohne LoRA:  3,800,000,000 trainierbare Parameter
Mit LoRA:      10,000,000 trainierbare Parameter (0.26%!)
```

### 7.3 Training-Loop erklÃ¤rt

```python
# Vereinfachter Training Loop
for epoch in range(num_epochs):
    for batch in train_dataloader:
        # 1. Forward Pass: Berechne Predictions
        outputs = model(batch)
        loss = outputs.loss

        # 2. Backward Pass: Berechne Gradienten
        loss.backward()

        # 3. Gradient Clipping: Verhindert explodierende Gradienten
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)

        # 4. Optimizer Step: Update Weights
        optimizer.step()

        # 5. Learning Rate Scheduler
        scheduler.step()

        # 6. Zero Gradients fÃ¼r nÃ¤chste Iteration
        optimizer.zero_grad()
```

### 7.4 Wichtige Training-Konzepte

#### Gradient Accumulation

```
Ohne Gradient Accumulation (batch_size=4):
    Batch 1 â†’ Forward â†’ Backward â†’ Update
    Batch 2 â†’ Forward â†’ Backward â†’ Update
    ...

Mit Gradient Accumulation (batch_size=4, accumulation=4):
    Batch 1 â†’ Forward â†’ Backward (sammle Gradienten)
    Batch 2 â†’ Forward â†’ Backward (sammle Gradienten)
    Batch 3 â†’ Forward â†’ Backward (sammle Gradienten)
    Batch 4 â†’ Forward â†’ Backward (sammle Gradienten) â†’ Update

    Effekt: Wie batch_size=16, aber nur Memory fÃ¼r 4!
```

#### Early Stopping

```python
early_stopping_callback = EarlyStoppingCallback(
    early_stopping_patience=3,     # Stoppt nach 3 Evals ohne Verbesserung
    early_stopping_threshold=0.001 # Minimale Verbesserung
)
```

**Warum Early Stopping?**

- Verhindert Overfitting
- Spart Trainingszeit
- WÃ¤hlt automatisch besten Checkpoint

---

## 8. Evaluation & Metriken

### 8.1 Datei: `evaluation/metrics.py`

Berechnet verschiedene QualitÃ¤ts-Metriken.

### 8.2 Metriken erklÃ¤rt

#### Exact Match Accuracy

```
Prediction: "J06.9"  vs  Reference: "J06.9"  â†’ Match! âœ“
Prediction: "J06.1"  vs  Reference: "J06.9"  â†’ Kein Match âœ—
```

#### Prefix Match Accuracy

BerÃ¼cksichtigt die ICD-10 Hierarchie:

```
3-Char Prefix:
  "J06.9" und "J06.1" â†’ "J06" = "J06" â†’ Match! âœ“

1-Char Prefix (Hauptkategorie):
  "J06.9" und "J10.0" â†’ "J" = "J" â†’ Match! âœ“
```

#### Precision, Recall, F1

```
                    TatsÃ¤chliche Klasse
                    Positiv    Negativ
Vorhergesagt  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Positiv       â”‚    TP    â”‚    FP    â”‚  â† Precision = TP/(TP+FP)
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Negativ       â”‚    FN    â”‚    TN    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
              Recall = TP/(TP+FN)

F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

**Wann welche Metrik?**

- **Precision wichtig:** Wenn falsche Positive teuer sind (z.B. unnÃ¶tige Behandlung)
- **Recall wichtig:** Wenn falsche Negative teuer sind (z.B. Ã¼bersehene Krankheit)
- **F1:** Balancierter Trade-off

### 8.3 Performance-Metriken

```python
metrics = {
    "latency_seconds": 0.05,         # Zeit pro Prediction
    "throughput_samples_per_sec": 20, # Predictions pro Sekunde
    "tokens_per_second": 100,         # Token-Generierungsrate
}
```

---

## 9. Experiment-Workflow

### 9.1 Schritt-fÃ¼r-Schritt Anleitung

#### Schritt 1: Environment einrichten

```bash
# Virtuelle Umgebung erstellen
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate    # Windows

# Dependencies installieren
pip install -e ".[dev]"
```

#### Schritt 2: Nur Baseline-Evaluation

```bash
# Testet LLM und SLM ohne Training
python main.py --experiment baseline
```

#### Schritt 3: VollstÃ¤ndiger Durchlauf

```bash
# Baseline + Training + Evaluation
python main.py --experiment full
```

#### Schritt 4: Nur Training (mit existierender Baseline)

```bash
python main.py --experiment training
```

#### Schritt 5: Ergebnisse analysieren

```bash
# Ã–ffne generierten Report
open outputs/reports/evaluation_report.html
```

### 9.2 CLI-Optionen

```bash
python main.py --help

Options:
  --experiment {baseline,training,full}
  --skip-training          # Nutze existierendes Modell
  --model-llm MODEL_NAME   # Override LLM
  --model-slm MODEL_NAME   # Override SLM
  --config PATH            # Eigene Config-Datei
```

### 9.3 Modelle anpassen

In `config/base_config.py`:

```python
# Standard-Konfiguration mit mehreren Baseline-LLMs:
# (ErmÃ¶glicht Vergleich verschiedener ModellgrÃ¶ÃŸen)
baseline_llm_names = [
    "Qwen/Qwen2.5-3B-Instruct",           # 3B Parameter - schnell
    "mistralai/Mistral-7B-Instruct-v0.3",  # 7B Parameter - bessere QualitÃ¤t
]

# FÃ¼r kleinere GPU (< 8GB VRAM):
baseline_llm_names = ["TinyLlama/TinyLlama-1.1B-Chat-v1.0"]
slm_name = "microsoft/phi-2"

# FÃ¼r grÃ¶ÃŸere GPU (16GB+ VRAM) - mit gated Models (Lizenz erforderlich):
baseline_llm_names = [
    "meta-llama/Llama-3.2-3B-Instruct",  # BenÃ¶tigt HuggingFace-Genehmigung
    "Qwen/Qwen2.5-3B-Instruct",
]
slm_name = "microsoft/Phi-3-mini-4k-instruct"
```

> **Hinweis:** FÃ¼r `meta-llama` Modelle mÃ¼ssen Sie die Nutzungsbedingungen auf 
> HuggingFace akzeptieren: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct

---

## 10. Best Practices & Troubleshooting

### 10.1 Memory-Probleme

**Symptom:** `CUDA out of memory`

**LÃ¶sungen:**

```python
# 1. Kleinere Batch Size
training.per_device_train_batch_size = 2

# 2. Mehr Gradient Accumulation
training.gradient_accumulation_steps = 8

# 3. Aktiviere 4-bit Quantisierung
model.slm_load_in_4bit = True

# 4. Aktiviere Gradient Checkpointing
training.gradient_checkpointing = True
```

### 10.2 Training konvergiert nicht

**Symptom:** Loss sinkt nicht

**LÃ¶sungen:**

```python
# 1. Learning Rate anpassen
training.learning_rate = 1e-5  # Versuche kleinere Werte

# 2. Mehr Warmup
training.warmup_steps = 1000

# 3. PrÃ¼fe Daten
# Sind Labels korrekt? Ist Formatierung konsistent?
```

### 10.3 Overfitting

**Symptom:** Train-Loss sinkt, Val-Loss steigt

**LÃ¶sungen:**

```python
# 1. Mehr Regularisierung
training.weight_decay = 0.05
training.lora_dropout = 0.1

# 2. Weniger KapazitÃ¤t
training.lora_r = 8

# 3. FrÃ¼her stoppen
training.early_stopping_patience = 2
```

### 10.4 Reproduzierbarkeit

FÃ¼r identische Ergebnisse bei jedem Lauf:

```python
# In config setzen:
experiment.seed = 42
experiment.deterministic = True

# Aber Achtung: deterministic=True macht Training ~10% langsamer!
```

---

## ğŸ“š Weitere Ressourcen

### Papers

- LoRA: https://arxiv.org/abs/2106.09685
- QLoRA: https://arxiv.org/abs/2305.14314
- Transformer: https://arxiv.org/abs/1706.03762

### Dokumentation

- HuggingFace Transformers: https://huggingface.co/docs/transformers
- PEFT (LoRA): https://huggingface.co/docs/peft
- BitsAndBytes: https://github.com/TimDettmers/bitsandbytes

### ICD-10

- WHO ICD-10: https://icd.who.int/browse10/2019/en
- DIMDI (Deutschland): https://www.bfarm.de/DE/Kodiersysteme/Klassifikationen/ICD/ICD-10-GM

---

## ğŸ¤ Beitragen

1. Fork das Repository
2. Erstelle Feature Branch: `git checkout -b feature/meine-feature`
3. Committe Ã„nderungen: `git commit -m "Add: Meine neue Feature"`
4. Push zum Branch: `git push origin feature/meine-feature`
5. Erstelle Pull Request

---

## ğŸ“„ Lizenz

MIT License - siehe LICENSE Datei

---

_Dieser Guide wurde erstellt, um Machine Learning Engineering Best Practices zu vermitteln.
Bei Fragen oder Problemen bitte ein Issue erstellen._
